{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":107469,"databundleVersionId":13058354,"sourceType":"competition"},{"sourceId":258701476,"sourceType":"kernelVersion"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output\n!pip install ultralytics\nclear_output()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-29T06:31:11.614421Z","iopub.execute_input":"2025-08-29T06:31:11.614646Z","iopub.status.idle":"2025-08-29T06:31:15.144122Z","shell.execute_reply.started":"2025-08-29T06:31:11.614628Z","shell.execute_reply":"2025-08-29T06:31:15.143308Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ultralytics import YOLO\nfrom pathlib import Path\nfrom PIL import Image\nimport csv\nimport os\nimport random\nimport torch\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\nrandom.seed(42)\ntorch.manual_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T06:31:15.145115Z","iopub.execute_input":"2025-08-29T06:31:15.145362Z","iopub.status.idle":"2025-08-29T06:31:17.323341Z","shell.execute_reply.started":"2025-08-29T06:31:15.145335Z","shell.execute_reply":"2025-08-29T06:31:17.322573Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x78ad66f534f0>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"def filter_invalid_boxes(boxes, scores, labels):\n    filtered_boxes, filtered_scores, filtered_labels = [], [], []\n    for b, s, l in zip(boxes, scores, labels):\n        if abs(b[2] - b[0]) > 1e-6 and abs(b[3] - b[1]) > 1e-6:\n            filtered_boxes.append(b)\n            filtered_scores.append(s)\n            filtered_labels.append(l)\n    return filtered_boxes, filtered_scores, filtered_labels\n    \ndef run_inference(models, image_sizes, test_images_path, agnostic_nms=False, iou=0.4, key=\"default\"):\n    image_paths = [p for p in Path(test_images_path).glob(\"*\") if p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]]\n    predictions = {}\n\n    for model_idx, model in enumerate(models):\n        model.eval()\n        model.training = False\n        predictions[model_idx] = {}\n        os.makedirs(f\"{key}/{model_idx}\", exist_ok=True)\n        \n        for size in image_sizes:\n            predictions[model_idx][size] = {}\n            pred = []\n            for img_path in image_paths:\n                image_id = img_path.stem\n                image = Image.open(img_path)\n                img_width, img_height = image.size\n\n                results = model.predict(source=str(img_path), conf=conf,iou=iou, max_det=600, agnostic_nms=agnostic_nms, augment=True, imgsz=size, verbose=False)\n                boxes, scores, labels = [], [], []\n\n                for result in results:\n                    if result.boxes is None:\n                        continue\n                    boxes = result.boxes.xyxy.cpu().numpy().tolist()\n                    scores = result.boxes.conf.cpu().numpy().tolist()\n                    labels = result.boxes.cls.cpu().numpy().tolist()\n\n                    norm_boxes = [\n                        [x1 / img_width, y1 / img_height, x2 / img_width, y2 / img_height]\n                        for x1, y1, x2, y2 in boxes\n                    ]\n                    norm_boxes, scores, labels = filter_invalid_boxes(norm_boxes, scores, labels)\n\n                predictions[model_idx][size][image_id] = {\n                    \"boxes\": norm_boxes,\n                    \"scores\": scores,\n                    \"labels\": labels\n                }\n                \n                if boxes:\n                    prediction_string = \" \".join(\n                        f\"{int(lbl)} {score:.6f} {(b[0]+b[2])/2:.6f} {(b[1]+b[3])/2:.6f} {(b[2]-b[0]):.6f} {(b[3]-b[1]):.6f}\"\n                        for b, score, lbl in zip(norm_boxes, scores, labels)\n                    )\n                else:\n                    prediction_string = \"no boxes\"\n\n                pred.append({\n                    \"image_id\": image_id,\n                    \"prediction_string\": prediction_string\n                })\n\n            # Save CSV per model and size\n            df = pd.DataFrame(pred)\n            csv_path = f\"{key}/{model_idx}/{size}.csv\"\n            df.to_csv(csv_path, index=False, quoting=csv.QUOTE_MINIMAL)\n            print(f\"[saved] {csv_path}\")\n            print(df.shape)\n            print(df.head(10))\n\n    return predictions\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T06:31:17.325223Z","iopub.execute_input":"2025-08-29T06:31:17.325561Z","iopub.status.idle":"2025-08-29T06:31:17.337997Z","shell.execute_reply.started":"2025-08-29T06:31:17.325542Z","shell.execute_reply":"2025-08-29T06:31:17.337341Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\n# === Config ===\n\nmodel_paths = [\n    \"/kaggle/input/falcon-multiclass-yolo-train/runs/detect/train/weights/best.pt\",\n    \"/kaggle/input/falcon-multiclass-yolo-train/runs/detect/train2/weights/best.pt\",\n    \"/kaggle/input/falcon-multiclass-yolo-train/runs/detect/train22/weights/best.pt\",\n    \"/kaggle/input/falcon-multiclass-yolo-train/runs/detect/train222/weights/best.pt\",\n    \"/kaggle/input/falcon-multiclass-yolo-train/runs/detect/train2222/weights/best.pt\",\n]\ntest_images_path = \"/kaggle/input/multi-class-object-detection-challenge/testImages/images\"\nconf = 0\nimage_sizes = [640, 800, 1056, 1376, 1600, 1920]\n\n\nmodels = [YOLO(path) for path in model_paths]\n\ntasks = {\"default\": (False, 0.4)}\n\nfor key, values in tasks.items():\n    agnms, iou = values\n    run_inference(models, image_sizes, test_images_path, iou=iou, agnostic_nms=agnms, key=key)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T06:31:17.338953Z","iopub.execute_input":"2025-08-29T06:31:17.339527Z","execution_failed":"2025-08-29T06:33:52.732Z"}},"outputs":[{"name":"stdout","text":"[saved] default/0/640.csv\n(229, 2)\n   image_id                                  prediction_string\n0  IMG_8712  0 0.988986 0.460025 0.488498 0.260656 0.247856...\n1  IMG_8949  0 0.992652 0.521739 0.514556 0.227738 0.252245...\n2  IMG_8778  0 0.987490 0.426535 0.736258 0.522379 0.450927...\n3  IMG_8723  0 0.977244 0.280729 0.509077 0.189260 0.302615...\n4  IMG_8771  1 0.977200 0.704487 0.497719 0.182001 0.209258...\n5  IMG_9164  0 0.988026 0.668358 0.495484 0.628854 0.350950...\n6  IMG_9946  0 0.950534 0.274385 0.144704 0.235058 0.289408...\n7  IMG_9953  1 0.975076 0.653702 0.620132 0.118390 0.179962...\n8  IMG_8796  1 0.974870 0.348341 0.531711 0.193522 0.237166...\n9  IMG_9951  1 0.392412 0.638941 0.559883 0.073106 0.108611...\n","output_type":"stream"}],"execution_count":null}]}